# Домашнее задание к занятию "10.6 Инцидент-менеджмент"

## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

> **Ответ:**    
>
> |       Постмортем            |       |
> |:--------------------------  |:----- |
> | Краткое описание инцидента  | 22 октября 2018 около 23 часов в следствии ошибок планирования и настройки инфраструктуры произошел сбой в работе сервисов GitHub выражавшийся в задержках и рассогласование выдаваемых пользователям данных в течении 24 часов и 11 минут. |
> | Предшествующие события      | Проводились плановые работы по замене неисправного сетевого оборудования. |
> | Причина инцидента           | Ошибки в настройке Orchestrator позволившие провести выборы реплик MySQL между регионами. |
> | Воздействие                 | Произошло рассогласование данных между региональными кластерами MySQL. Что привело к появлению непоследовательной информации на веб-сайте. |
> | Обнаружение                 | Неполадки были зафиксированы системами мониторинга и замечены дежурными инженерами. |
> | Реакция                     | Дежурные инженеры присвоили проблеме желтый статус и оповестили координатора инцидентов, который присвоил проблеме красный статус и привлек к решению проблемы команду разработчиков баз данных и другие команды. Акцент был сделан на сохранности данных, а не на доступности сервисов. |
> | Восстановление              | Инженерами были временно заблокированы внутренние инструменты развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. Выработан и осуществлен план действий по восстановлению данных кластеров из бэкапов и репликации данных между ними. |
> | Таймлайн                    | 22:52 работы по замене сетевого оборудования. |
> |								| 22:54 множественные алерты в системах мониторига по сбоям. |
> | 					        | 23:07 блокировка внутренних инструментов развертывания. Привлечение оповещение координатора. |
> | 					        | 23:13 привлечена команда разработчиков баз данных. |
> | 					        | 23:19 приостановлено выполнение заданий, пишущих метаданные (push-запросы). Принято решение о приоритете сохранности данных перед доступностью сервисов. |
> | 					        | 00:05 разработка плана устранения неисправностей с помощью восстановления данных из бэкапа с последующим реплицированные по кластерам. |
> | 					        | 00:41 начато восстановление из бэкапа по всем затронутым кластерам. |
> | 					        | 06:51 завершение восстановления из бэкапа нескольких кластеров и начало репликации. Уточнение нагрузки и расчетного времени восстановления. |
> | 					        | 07:46 публикация сообщения о проблеме в блоге GitHub (ранее публикация была осложнена блокировкой инструментов развертывания). |
> | 					        | 11:12 восстановленны из бэкапа все primary базы, репликация стала занимать все больше времени. |
> | 					        | 13:15 начали предоставлять дополнительные реплики для чтения MySQL в общедоступном облаке. Как только они стали доступны, стало проще распределять объем запросов на чтение по большему количеству серверов. |
> | 					        | 16:24 окончание синхронизации реплик. Переход на исходную топологию. Начало обработки накопившихся данных. |
> | 					        | 16:45 балансировка возросшей нагрузки. Увеличение внутреннего TTL для накопившихся данных. |
> | 					        | 23:03 обработаны все незавершенные сборки веб-приложений и страниц, подтверждена целостность и корректность работы всех систем. Статус сайта обновлен до зеленого. |
> | Последующие действия        | Далее проводилась работа по согласованию 954 записей сделанных во время сбоя. |
> | 					        | По итогам: |
> | 					        | - произведена правильная настройка Orchestrator; |
> | 					        | - ускорен переход на новый механизм отчетности о состоянии компонетов системы для пользователей; |
> | 					        | - проработка инициативы по поддержке обслуживания трафика GitHub из нескольких центров обработки данных в активном/активном/активном режиме. Для поддержки резервирования на уровне N+1. Это позволит переносить полный отказ одного сбоя центра обработки данных без воздействия на пользователя. |

---

Сергей Андрюнин (преподаватель)
30 августа 2021 13:40

Тимофей спасибо за выполнение ДЗ, все верно зачет.
