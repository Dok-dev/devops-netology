# Домашнее задание «6.6. Troubleshooting»

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя    

**Ответ:**    
```json
// 1. запрос списка текущих операций происходящих в базе "My_DB" более трех минут:
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 120 },
     "ns" : /^My_DB\./
   }
)

// 2. убить операцию на основе опид:
db.killOp(<opid>)
```
Так же возможно воспользоваться профайлером:
```json
db.setProfilingLevel(1, 120)
    { "was" : 0,
      "slowms" : 100,
      "ok" : 1 
    }
db.getProfilingStatus()
    { "was" : 1,
      "slowms" : 120
     }
```
Данные будут помещены в коллекцию system.profile.

- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

**Ответ:**    
Сначала следует проверить корректность запроса на предмет создание лишней нагрузки на сервис. Для этого можно использовать метод `.explain("executionStats")`.    
В некоторых случаях можно попробовать ограничить время его выполнения в коде:
```
db.collection_name.find(<query_string>).maxTimeMS(<time_limit>)
```
Дальше уже следует смотреть в сторону оптимизации работы БД, в частности индексов.    
Если и там все хорошо, то следует заняться масштабированием.    
Возможно, стоит убедиться в правильности выбора СУБД.

---

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?
 
**Ответ:**    
Возможно, недостаточно оперативной памяти для такого количества реплик в рамках одного сервера. 
И записанные значения стали очищаться раньше истечения TTL.    
Затем были исчерпаны настроенные лимиты политик удаления ключей при достижении maxmemory (volatile-lru, volatile-ttl, volatile-random, allkeys-lru, allkeys-random).    
После чего Redis некуда размещать новые потоки данных, и происходит полная блокировка процессов записи.


---

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

**Ответ:**    
Если нет никаких проблем с сетью, то согласно документации наиболее вероятна проблема с таймаутом при ожидании ответа на запрос, по умолчанию 30 сек.    
Такое может происходить при большом количестве строк в выборке.    
Для устранения данной проблемы нужно:
 - увеличить значение `net_read_timeout`; 
 - подумать над оптимизацией таблицы, посмотреть правильно ли организованна индексация для таких запросов;   
 - так же проверить сам запрос на предмет излишней нагрузки на СУБД;   
 - возможно стоит расмореть переход на более производительную СУБД для подобных данных и запросов.

В некоторых случаях может возникать проблема со значениями BLOB-объектов, которые больше, чем `max_allowed_packet`, что может вызвать эту ошибку у некоторых клиентов.    
Тогда это зачастую сопровождается ошибкой `ER_NET_PACKET_TOO_LARGE`. В данном случае нужно увеличить значение `max_allowed_packet`.


---

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевезти гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

**Ответ:**    
Postgres (старое название postmaster) завершает Out-Of-Memory Killer в ОС после исчерпания доступной RAM.    
Необходимо провести:
 - анализ колличества соединений с БД;
 - провести профилирование самих запросов к БД, на предмет ресурсоемкости и последующую оптимизацию;
 - провести оптимизацию настроек PostgreSQL касающихся работы с памятью (https://postgrespro.ru/docs/postgresql/12/runtime-config-resource#RUNTIME-CONFIG-RESOURCE-MEMORY);
 - отрегулировать параметры Out-Of-Memory Killer и использования swap, если проблема достаточно редкая. Возможно разрешить небольшой уход в swap для сохранения работоспособности сервиса, выставив vm.overcommit_memory = 2 и отрегулировав overcommit_ratio чуть больше 1 (по умолчанию 60), что бы не снижать быстродействие.
